#!/usr/bin/env python

# kano-logs
#
# Copyright (C) 2014 Kano Computing Ltd.
# License: http://www.gnu.org/licenses/gpl-2.0.txt GNU General Public License v2
#
# View and manipulate kano logs
#
# Call kano-logs -h for help
#

import os
import re
import sys
import json
import pydoc
import datetime
import argparse

if __name__ == '__main__' and __package__ is None:
    dir_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    if dir_path != '/usr':
        sys.path.insert(0, dir_path)

import kano.logging as logging
from kano.logging import logger
from kano.colours import decorate_string_only_terminal, decorate_with_preset
from kano.utils import enforce_root
import pyinotify

# Used for looking at logs off the pi. See -d option
force_log_dirs = None

def get_logfiles(app=None):
    log_dirs = [logging.SYSTEM_LOGS_DIR]
    if os.getuid() != 0:
        log_dirs.append(logging.USER_LOGS_DIR)
    else:
        for f in os.listdir('/home'):
            user_log_dir = '/home/{}/.kano-logs'.format(f)
            if os.path.isdir(user_log_dir):
                log_dirs.append(user_log_dir)

    if force_log_dirs is not None:
        log_dirs = force_log_dirs

    logfiles = []
    for d in log_dirs:
        if app is not None:
            path = os.path.join(d, app + ".log")
            if os.path.exists(path):
                logfiles.append(path)
        else:
            if os.path.exists(d):
                for log in os.listdir(d):
                    logfiles.append(os.path.join(d, log))

    return logfiles


def get_log_data(path):
    data = []
    app_name = re.sub(r"\.log$", "", os.path.basename(path))
    with open(path, "r") as f:
        for line in f:
            try:
                line_data = json.loads(line)
                line_data["app_name"] = app_name
                data.append(line_data)
            except:
                # Couldn't read the line, skip it
                continue

    return data


def show_logs(app=None, linearised=False):
    logfiles = get_logfiles(app)

    output = ""
    if linearised:
        all_data = []
        for log in logfiles:
            all_data += get_log_data(log)

        all_data.sort(lambda a, b: cmp(a["time"], b["time"]))
        output += format_log_data(all_data)
    else:
        for log in logfiles:
            label = decorate_string_only_terminal("LOGFILE", "green")
            output += "{}: {}\n".format(label, log)
            output += format_log_data(get_log_data(log)) + "\n"

    if len(output) > 0:
        pydoc.pipepager(output, cmd='less -R')


def format_log_data(data, default_app_name=""):
    output = ""

    for entry in data:
        app_name = default_app_name
        if "app_name" in entry:
            app_name = entry["app_name"]

        dt = datetime.datetime.fromtimestamp(entry["time"])
        time = dt.strftime('%Y-%m-%d %H:%M:%S')
        output += "{} {}[{}] {} {}\n".format(
            decorate_string_only_terminal(time, "cyan"),
            app_name,
            decorate_string_only_terminal(entry["pid"], "yellow"),
            decorate_with_preset(entry["level"], entry["level"], True),
            entry["message"]
        )

    return output


class EventHandler(pyinotify.ProcessEvent):
    def __init__(self, app_name=None):
        self._app_name_filter = app_name
        self._last_map = {}

        all_data = []
        for path in get_logfiles(app_name):
            data = self._process_file(path)
            all_data += data[-10:]

        all_data.sort(lambda a, b: cmp(a["time"], b["time"]))
        print format_log_data(all_data),

    def process_IN_CREATE(self, event):
        new = self._process_file(event.pathname)
        print format_log_data(new),

    def process_IN_MODIFY(self, event):
        new = self._process_file(event.pathname)
        print format_log_data(new),

    def _process_file(self, path):
        app_name = re.sub(r"\.log$", "", os.path.basename(path))
        if self._app_name_filter is not None and \
           self._app_name_filter != app_name:
            return []

        data = []
        new_data = []
        with open(path, "r") as f:
            for line in f:
                try:
                    line_data = json.loads(line)
                    line_data["app_name"] = app_name
                except:
                    # ignore malformed lines
                    continue

                data.append(line_data)

            if len(data) > 0:
                data.sort(lambda a, b: cmp(a["time"], b["time"]))

                if path in self._last_map:
                    latest = self._last_map[path]
                    new_data = [log for log in data if log['time'] > latest]
                else:
                    new_data = data

                self._last_map[path] = data[-1]["time"]

        return new_data


def watch_logs(app=None):
    wm = pyinotify.WatchManager()

    handler = EventHandler(app)
    notifier = pyinotify.Notifier(wm, handler)

    mask = pyinotify.IN_CREATE | pyinotify.IN_MODIFY
    dirs = [logging.SYSTEM_LOGS_DIR, logging.USER_LOGS_DIR]
    wm.add_watch(dirs, mask, rec=True, auto_add=True)

    notifier.loop()


def process_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-d", "--log-dir",
        help="extract from a different dir (for off-pi analysis)",
        type=str
    )

    subparsers = parser.add_subparsers(
        title="Subcommands",
        description="These are the commands you can use with kano-logs",
        help="the available subcommands"
    )

    show = subparsers.add_parser("show", help="display logs")
    show.set_defaults(which="show")
    show.add_argument(
        "app",
        type=str,
        help="the application to show logs for",
        default=None,
        nargs="?"
    )

    show.add_argument(
        "-w", "--watch",
        help="watch the logs and print new messages as they arrive",
        action="store_const",
        const=True,
        default=False
    )

    show.add_argument(
        "-l", "--linearised",
        help="print a single list of entries sorted by time",
        action="store_const",
        const=True,
        default=False
    )

    config = subparsers.add_parser("config", help="configure logging")
    config.set_defaults(which="config")
    config.add_argument(
        "-l", "--log-level",
        help="set log level",
        type=str,
        nargs="?"
    )

    config.add_argument(
        "-o", "--output-level",
        help="set output level",
        type=str,
        nargs="?"
    )

    config.add_argument(
        "-s", "--show-value",
        help="print a configuration option",
        type=str
    )

    args = parser.parse_args()
    return vars(args)


def main():
    global force_log_dirs

    args = process_args()

    if 'log_dir' in args and args['log_dir']:
        force_log_dirs = [args['log_dir']]

    if args["which"] == "show":
        if args["watch"]:
            watch_logs(args["app"])
        else:
            show_logs(args["app"], args["linearised"])
    elif args["which"] == "config":
        if args["log_level"] is None and args["output_level"] is None and args["show_value"] is None:
            ll = logger.get_log_level()
            dl = logger.get_output_level()
            print "Logging to file set to {}".format(decorate_with_preset(ll, ll), True)
            print "Output set to {}".format(decorate_with_preset(dl, dl), True)
            return 0

        if args["show_value"] is not None:
            if args["show_value"] == "log_level":
                print logger.get_log_level()
            elif args["show_value"] == "output_level":
                print logger.get_output_level()
            return 0

        enforce_root("ERROR: Must be root to change the modes")

        if args["log_level"] is not None:
            logging.set_system_log_level(args["log_level"])

        if args["output_level"] is not None:
            logging.set_system_output_level(args["output_level"])

    return 0

if __name__ == "__main__":
    sys.exit(main())
